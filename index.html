<!DOCTYPE html>
<!--
My online resume
-->
<html><head>
<title>Yicheng (Eli) Wu's Homepage</title>

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css">
<style type="text/css">
 @import url("http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,300italic,600,600italic");


body
{
	font-family: 'Source Sans Pro', sans-serif;
    background-color : #CDCDCD;
    font-size: 17px;
}
    .content
	{
    		width : 1300px;
    		padding : 25px 30px;
    		margin : 25px auto;
    		background-color : #fff;
    		box-shadow: 0px 0px 10px #999;
    		border-radius: 15px; 
	}	
	table
	{
		padding: 5px;
	}
	
	table.pub_table,td.pub_td1,td.pub_td2
	{
		padding: 8px;
		width: 1100px;
        border-collapse: separate;
        border-spacing: 15px;
        margin-top: -5px;
	}

	td.pub_td1
	{
		width:50px;
	}
    td.pub_td1 img
    {
        height:120px;
        width: 160px;
    }
	
	div#container
	{
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
		text-align: justify;
		position: relative;
		background-color: #FFF;
	}
	div#DocInfo
	{
		color: #3B3B3B;
		height: 158px;
	}
	h4,h3,h2,h1
	{
		color: #3B3B3B;
	}
	h2
	{
		font-size:130%;
	}
	p
	{
		color: #5B5B5B;
		margin-bottom: 50px;
	}
	p.caption
	{
		color: #9B9B9B;
		text-align: left;
		width: 600px;
	}
	p.caption2
	{
		color: #9B9B9B;
		text-align: left;
		width: 800px;
	}
	#header_img
	{
		position: absolute;
		top: 0px; right: 0px;
    }
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
   
    table.pub_table tr {
        outline: thin dotted #666666;
    }
    .papericon {
        border-radius: 8px; 
        -moz-box-shadow: 3px 3px 6px #888;
        -webkit-box-shadow: 3px 3px 6px #888;
        box-shadow: 3px 3px 6px #888;
    }
</style>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('send', 'pageview');

</script>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-23931362-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

    var myPix = new Array("images/id.jpg")
    function choosePic() {
        var randomNum = Math.floor(Math.random() * myPix.length);
        document.getElementById("myPicture").src = myPix[randomNum];
    };

</script>
</head>


<body>
<div class="content">
	<div id="container">
<center>
	<table>
	<tbody><tr>
	<td><img id="myPicture" src="images/id.jpg" style="float:left; padding-right:10px" height="200px"></td>
	<td>
	<div id="DocInfo">
		<h1><strong>Yicheng(Eli) Wu 吴轶成</strong></h1>
						<h2>Ph.D. Candidate</h2>
							Affiliation: Faculty of Information Technology, Monash University<br />
							Current Address: Clayton, VIC 3168, Australia<br />
							Email: yicheng[dot]wu[at]monash[dot]edu<br />
							<a href="https://scholar.google.com/citations?user=_h1y48MAAAAJ&hl=en">Google Scholar</a>
							&bull; <a href="https://www.researchgate.net/profile/Yicheng_Wu5">ResearchGate</a>
							&bull; <a href="https://www.linkedin.com/in/yicheng-wu-58a46b150/">LinkedIn</a>
							&bull; <a href="https://github.com/ycwu1997">GitHub</a>
						</div><br>
	</td>
	</tr>
	</tbody></table>
</center>
<br>
<!-- <center><h2><strong>This is a new AI era </strong></h2></center> -->
	<h2><strong>Biography</strong></h2>
	<ul>
		<li><strong>Introduction</strong></li>
			<ul>
			Hi, I am currently a final-year Ph.D. student at Monash University, where my research focuses on developing a robust learning framework for medical image analysis. 
			Some of my earlier works are about studying imperfect learning scenarios, such as limited/heterogeneous data training, weakly/semi-/unsupervised image segmentation, 
			as well as the analysis of specific objects like retinal vessels or brain lesions.
			</ul>
		<li><strong>Education Backgrounds</strong></li>
			<ul>
			<li>2021.06-Present &nbsp; &bull;&nbsp; Ph.D. Candidate &nbsp; &bull;&nbsp; Supervisor: <a href="https://jianfei-cai.github.io/">Prof. Jianfei Cai</a> (IEEE Fellow) and <a href="https://zongyuange.github.io/">A/Prof. Zongyuan Ge</a>.<br></li> 
			<h6>Faculty of Information Technology, Monash University, Australia</h6>
			<li>2017.09-2020.04 &nbsp; &bull;&nbsp;&nbsp; M.E. Degree &nbsp;  &nbsp;&bull;&nbsp; Supervisor: <a href="https://teacher.nwpu.edu.cn/en/yongxia.html">Prof. Yong Xia</a>.<br></li>
			<h6>School of Computer Science and Engineering, Northwestern Polytechnical University, China</h6>
			<li>2018.11-2019.05 &nbsp; &bull;&nbsp; &nbsp;Visiting Student &nbsp; &bull;&nbsp; Supervisor: <a href="https://weidong-tom-cai.github.io/">A/Prof. Weidong(Tom) Cai</a> and <a href="http://www.cse.unsw.edu.au/~ysong/">A/Prof. Yang Song</a>.<br></li>
			<h6>School of Computer Science, The University of Sydney, Australia</h6>
			<li>2013.09-2017.06 &nbsp; &bull;&nbsp; B.E. Degree &nbsp; &bull;&nbsp; Supervisor: <a href="https://teacher.nwpu.edu.cn/en/yongxia.html">Prof. Yong Xia</a>.<br></li>
			<h6>School of Computer Science and Engineering, Northwestern Polytechnical University, China</h6>
			</ul> 
		<li><strong>Working Experiences</strong></li>
			<ul>
			<li>2023.12-Present &nbsp;&nbsp; &bull;&nbsp;&nbsp; Research Intern &nbsp; &bull;&nbsp; Shanghai AI Lab</li>
			<li>2023.03-2023.12 &nbsp;&nbsp; &bull;&nbsp;&nbsp; Research Assistant &nbsp; &bull;&nbsp; Monash, Faculty of IT</li>
			<li>2020.08-2021.05 &nbsp;&nbsp; &bull;&nbsp;&nbsp; Research Intern &nbsp; &bull;&nbsp; Alibaba DAMO Academy</li>
			<li>2019.05-2019.09 and 2020.05-2020.08 &nbsp;&bull;&nbsp; Research Intern &nbsp; &bull;&nbsp; Deepwise AI Lab</li>
			</ul>
	</ul>
    <h2><strong>News</strong></h2>
	<div style="height: 230px; overflow: auto;">
    	<ul>
		<li>[2024.03.04] We will host a grand challenge about multi-rater medical image segmentation in ACM MM 2024.</li>
		<li>[2024.02.27] One paper was accepted by CVPR 2024. Paper and Code will be released soon.</li>	
		<li>[2023.12.07] One journal paper was accepted by IJCV (IF-2023: 19.5), see <a href="https://doi.org/10.1007/s11263-023-01975-8">Paper</a> and <a href="https://github.com/wu-zhonghua/RAC-Net">Code</a>. Congrats. to <a href="https://wu-zhonghua.github.io/">Zhonghua</a>.</li>
		<li>[2023.10.12] I am very pleased to be selected as an IEEE Transactions on Medical Imaging (TMI) Distinguished Reviewer.</li>
		<li>[2023.07.25] I am very pleased to receive the <a href="https://www.monash.edu/it/news/2023/deans-awards-for-excellence-in-research">2023-FIT-Dean's Award</a> for Excellence in Research by a Graduate Research Student.</li>
		<li>[2023.07.11] One paper was early accepted by MICCAI 2023, about <a href="https://doi.org/10.1007/978-3-031-43993-3_1">Heterogeneous Data Training</a>.</li>
		<li>[2022.07.04] One paper was accepted by ECCV 2022, about <a href="https://doi.org/10.1007/978-3-031-19821-2_5">Weakly-Supervised Point Cloud Segmentation</a>.</li>
		<li>[2022.07.01] One journal paper was accepted by MedIA (IF-2022: 13.828), see <a href="https://doi.org/10.1016/j.media.2022.102530">here</a>.</li>
		<li>[2022.06.06] One journal paper was accepted by IEEE JBHI (IF-2022: 7.021), see <a href="https://doi.org/10.1109/JBHI.2022.3182471">here</a>. Congrats. to Yiwen.</li>
		<li>[2022.06.03] Two papers were accepted by MICCAI 2022, about <a href="https://doi.org/10.1007/978-3-031-16443-9_4">Semi-supervised Segmentation</a> and <a href="https://doi.org/10.1007/978-3-031-16437-8_44">Long-tailed Classification</a>.</li>
		<li>[2022.03.03] One joint paper was accepted by CVPR 2022, about <a href="http://dx.doi.org/10.1109/cvpr52688.2022.00939">Unsupervised Proposal Generation</a>.</li>
		<li>[2021.06.11] One paper was accepted by MICCAI 2021.</li>
        <li>[2020.08.01] During my gap year, I will work as a research intern at DAMO Academy, Alibaba Group.</li>
		<li>[2020.05.12] I received the M.E. degree from Northwestern Polytechnical University, supervised by <a href="https://teacher.nwpu.edu.cn/en/yongxia.html">Prof. Yong Xia</a>.</li>
		<li>[2020.02.27] One journal paper was accepted by Neural Networks (IF-2020: 8.050).</li>
		<li>[2019.06.05] One paper was accepted by MICCAI 2019.</li>
		<li>[2018.05.31] I was selected as a joint master student supported by the China Scholarship Council (CSC).</li>
		<li>[2018.05.30] One paper was accepted by MICCAI 2018.</li>
		<li>[2017.06.20] I received the B.E. degree from Northwestern Polytechnical University, supervised by <a href="https://teacher.nwpu.edu.cn/en/yongxia.html">Prof. Yong Xia</a>.</li>
    	</ul>
	</div>
	<br>
	<h2><strong>Representative Publications </strong></h2> 
	<ul>
		* and <sup>†</sup> indicates the corresponding authorship and equal contribution, respectively.
	</ul>
	<h5><strong>Recent Works</strong></h5>
	<table class="pub_table" >
		<tbody>
			<tr>
				<td class="pub_td1"><img src="images/versemi.png" class="papericon"></td>
				<td class="pub_td2">Qingjie Zeng, Yutong Xie, Zilin Lu, Mengkang Lu, <u>Yicheng Wu</u>, and Yong Xia<br><b>
					Segment Together: A Versatile Paradigm for Semi-Supervised Medical Image Segmentation</b><br> arXiv Print, 2023. [<a href="https://arxiv.org/pdf/2311.11686.pdf">Paper</a>]
			</td></tr>
			<tr>
				<td class="pub_td1"><img src="images/openssl.png" class="papericon"></td>
				<td class="pub_td2">Lie Ju, <u>Yicheng Wu</u>, Feng Wei, Zhen Yu, Lin Wang, Zhuoting Zhu and Zongyuan Ge*<br><b>
					Towards Open-Scenario Semi-supervised Medical Image Classification</b><br> arXiv Print, 2023. [<a href="https://arxiv.org/pdf/2304.04059.pdf">Paper</a>]
			</td></tr>
		</tbody></table>

	<h5><strong>Task-based Works(Application-oriented, 2023-Now)</strong></h5>
	<table class="pub_table" >
		<tbody>
			<tr>
				<td class="pub_td1"><img src="images/miccai23.png" class="papericon"></td>
				<td class="pub_td2"><u>Yicheng Wu*</u>, Zhonghua Wu, Hengcan Shi, Bjoern Picker, Winston Chong, and Jianfei Cai<br><b>
					CoactSeg: Learning from Heterogeneous Data for New Multiple Sclerosis Lesion Segmentation</b><br> MICCAI 2023, vol. 14227, pp. 3-13, 2023. [<a href="https://doi.org/10.1007/978-3-031-43993-3_1">Paper</a>, <a href="https://github.com/ycwu1997/CoactSeg">Code</a>]
			</td></tr>
		</tbody></table>

	<h5><strong>Data-based Works(Semi-supervised Learning, 2020-Now)</strong></h5>
	<table class="pub_table" >
	<tbody>
		<tr>
			<td class="pub_td1"><img src="images/MC-Net+.jpg" class="papericon"></td>
			<td class="pub_td2"><u>Yicheng Wu*</u>, Zongyuan Ge, Donghao Zhang, Minfeng Xu, Lei Zhang, Yong Xia and Jianfei Cai<br><b>
				Mutual Consistency Learning for Semi-supervised Medical Image Segmentation</b><br> Medical Image Analysis (IF-2022: 13.828), vol. 81, pp. 102530, 2022. [<a href="https://doi.org/10.1016/j.media.2022.102530">Paper</a>, <a href="https://github.com/ycwu1997/MC-Net">Code</a>]
		 </td></tr>
		 <tr>
			<td class="pub_td1"><img src="images/ijcv23.jpg" class="papericon"></td>
			<td class="pub_td2">Zhonghua Wu<sup>†</sup>, <u>Yicheng Wu</u><sup>†</sup>, Guosheng Lin* and Jianfei Cai<br><b>
				Reliability-Adaptive Consistency Regularization for Weakly-Supervised Point Cloud Segmentation</b><br> International Journal of Computer Vision (IF-2023: 19.5), 2024. [<a href="https://doi.org/10.1007/s11263-023-01975-8">Paper</a>, <a href="https://github.com/wu-zhonghua/RAC-Net">Code</a>]
		</td></tr>
		<tr>
			<td class="pub_td1"><img src="images/miccai22.png" class="papericon"></td>
			<td class="pub_td2"><u>Yicheng Wu*</u>, Zhonghua Wu, Qianyi Wu, Zongyuan Ge, and Jianfei Cai<br><b>
				Exploring Smoothness and Class-Separation for Semi-supervised Medical Image Segmentation</b><br>MICCAI 2022, vol. 13435, pp. 34-43, 2022. [<a href="https://doi.org/10.1007/978-3-031-16443-9_4">Paper</a>, <a href="https://github.com/ycwu1997/SS-Net">Code</a>]
		 </td></tr>
		<tr>
			<td class="pub_td1"><img src="images/miccai21.png" class="papericon"></td>
			<td class="pub_td2"><u>Yicheng Wu</u>, Minfeng Xu, Zongyuan Ge, Jianfei Cai*, and Lei Zhang<br><b>
				Semi-supervised Left Atrium Segmentation with Mutual Consistency Training</b><br>MICCAI 2021, vol. 12902, pp. 297-306, 2021. [<a href="https://doi.org/10.1007/978-3-030-87196-3_28">Paper</a>, <a href="https://github.com/ycwu1997/MC-Net">Code</a>]
        </td></tr>
		<tr>
			<td class="pub_td1"><img src="images/eccv22.jpg" class="papericon"></td>
			<td class="pub_td2">Zhonghua Wu, <u>Yicheng Wu</u>, Guosheng Lin*, Jianfei Cai, and Chen Qian<br><b>
				Dual Adaptive Transformations for Weakly Supervised Point Cloud Segmentation</b><br> ECCV 2022, vol. 13691, pp. 78-96, 2022. [<a href="https://doi.org/10.1007/978-3-031-19821-2_5">Paper</a>, <a href="https://github.com/wu-zhonghua/DAT">Code</a>]
		</td></tr>
		<tr>
			<td class="pub_td1"><img src="images/miccai22_joint.png" class="papericon"></td>
			<td class="pub_td2">Lie Ju, <u>Yicheng Wu</u>, Lin Wang, Zhen Yu, Xin Zhao, Xin Wang, Paul Bonnington and Zongyuan Ge*<br><b>
				Flexible Sampling for Long-tailed Skin Lesion Classification</b><br> MICCAI 2022, vol. 13433, pp. 462-471, 2022. [<a href="https://doi.org/10.1007/978-3-031-16437-8_44">Paper</a>, <a href="https://github.com/PyJulie/FlexSampling">Code</a>]
		</td></tr>
		<!--
		-->
	</tbody></table>
	<h5><strong>Structure-based Works(2D/3D Vessel Segmentation, before 2020)</strong></h5>
	<table class="pub_table" >
	<tbody>
		<tr>
			<td class="pub_td1"><img src="images/jbhi22.png" class="papericon"></td>
			<td class="pub_td2">Yiwen Ye<sup>†</sup>, Chengwei Pan<sup>†</sup>, <u>Yicheng Wu</u>, Shuqi Wang, and Yong Xia*<br><b>
				MFI-Net: Multiscale Feature Interaction Network for Retinal Vessel Segmentation</b><br>IEEE Journal of Biomedical and Health Informatics (IF-2022: 7.021), vol. 26(9), pp. 4551-4562, 2022. [<a href="https://doi.org/10.1109/JBHI.2022.3182471">Paper</a>]
		</td></tr>

		<tr>
			<td class="pub_td1"><img src="images/nn2020.png" class="papericon"></td>
			<td class="pub_td2"><u>Yicheng Wu</u>, Yong Xia*, Yang Song, Yanning Zhang, and Weidong Cai<br><b>
				NFN+: A Novel Network Followed Network for Retinal Vessel Segmentation</b><br>Neural Networks (IF-2020: 8.050), vol. 126, pp. 153-162, 2020. [<a href="https://doi.org/10.1016/j.neunet.2020.02.018">Paper</a>]
			</td></tr>

		<tr>
			<td class="pub_td1"><img src="images/miccai19.svg" class="papericon"></td>
			<td class="pub_td2"><u>Yicheng Wu</u>, Yong Xia*, Yang Song, Donghao Zhang, Dongnan Liu, Chaoyi Zhang, and Weidong Cai<br><b>
				Vessel-Net: Retinal Vessel Segmentation under Multi-path Supervision</b><br>MICCAI 2019, vol. 11764, pp. 264-272, 2019. [<a href="https://doi.org/10.1007/978-3-030-32239-7_30">Paper</a></h4>]
			</td></tr>

		<tr>
			<td class="pub_td1"><img src="images/miccai18.png" class="papericon"></td>
			<td class="pub_td2"><u>Yicheng Wu</u>, Yong Xia*, Yang Song, Yanning Zhang, and Weidong Cai<br><b>
				Multiscale Network Followed Network Model for Retinal Vessel Segmentation</b><br>MICCAI 2018, vol. 11071, pp. 119-126, 2018. [<a href="https://doi.org/10.1007/978-3-030-00934-2_14">Paper</a>]
			</td></tr>
	</tbody></table>
    <h2><strong>Awards</strong></h2>
        <ul>
			<li>[01] 2023  &nbsp;&bull;&nbsp; IEEE Transactions on Medical Imaging (TMI) Distinguished Reviewer </li>
			<li>[02] 2023 &nbsp;&bull;&nbsp; <a href="https://www.monash.edu/it/news/2023/deans-awards-for-excellence-in-research">2023-FIT-Dean's Award</a> for Excellence in Research by a Graduate Research Student </li>
			<li>[03] 2021-2024  &nbsp;&bull;&nbsp; Monash Graduate Scholarship (MGS) and Monash International Tuition Scholarship (MITS) </li>
            <li>[04] 2020  &nbsp;&bull;&nbsp; NPU Excellent Postgraduate Thesis Award (Top 3%)</li>
			<li>[05] 2019-2020  &nbsp;&bull;&nbsp; NPU Key Seed Foundation of Innovation and Creation for Graduate Students</li>
			<li>[06] 2019  &nbsp;&bull;&nbsp; Inspur Postgraduate Scholarship</li>
			<li>[07] 2018-2019 &nbsp;&bull;&nbsp; Scholarship from China Scholarship Council (Joint Master Student)</li>
			<li>[08] 2018  &nbsp;&bull;&nbsp; SJTU-USYD Research Conversazione Best Research Presentation</li>
			<li>[09] 2017  &nbsp;&bull;&nbsp; NPU Excellent Undergraduate Thesis Award (Top 7%)</li>
		</ul>    
	<h2><strong>Academic Activities</strong></h2>
	<ul>
		<h5><li>Conference Reviews</li></h5>
		    <ul>
			<li>MICCAI 2019-2024</li>
			<li>NeurIPS 2023; ICLR 2024; ICML 2024</li>
			<li>CVPR 2022, 2023, 2024; ICCV 2023; ECCV 2022, 2024</li>
			</ul>
	</ul>
	<ul>
		<h5><li>Journal Reviews</li></h5>
			<ul>
			<li>Medical Image Analysis (MedIA)</li>
			<li>IEEE Transactions on Medical Imaging (TMI)</li>
			<li>International Journal of Computer Vision (IJCV)</li>
			<li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
			<li>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</li>
			<li>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
			<li>Computer Methods and Programs in Biomedicine</li>	
		</ul>
	</ul>
	<ul>
		<li>[01] 06-13 October 2023: MICCAI 2023, Canada <strong><i>(Poster)</i></strong></li>
		<li>[02] 18-22 September 2022: MICCAI 2022, Singapore <strong><i>(Poster)</i></strong></li>
		<li>[03] 27 September-01 October 2021: MICCAI 2021, Virtual Conference <strong><i>(Poster)</i></strong></li>
		<li>[04] 04-08 October 2020: OMIA7, Virtual Workshop <strong><i>(Online Presentation)</i></strong></li>
		<li>[05] 13-17 October 2019: MICCAI 2019, Shenzhen, China <strong><i>(Poster)</i></strong></li>
		<li>[06] 24 September 2019: MICS Webinar-MICCAI Conference <strong><i>(Online Oral Presentation)</i></strong></li>
		<li>[07] 13-14 July 2019: Medical Imaging Computing Seminar (MICS 2019), Suzhou, China <strong><i>(Poster)</i></strong></li>
		<li>[08] 23-26 November 2018: PRCV 2018, Guangzhou, China <strong><i>(Poster)</i></strong></li>
		<li>[09] 16-20 September 2018: MICCAI 2018, Granada, Spain <strong><i>(Poster)</i></strong></li>
		<li>[10] 20-22 April 2018: The 8th Vision and Learning Seminar (VALSE 2018), Dalian, China</li>
    </ul>
	<h2><strong>Curiosity</strong></h2>
	<ul>
		<h6>古人之观于天地、山川、草木、虫鱼、鸟兽，往往有得，以其求思之深而无不在也。夫夷以近，则游者众；险以远，则至者少。而世之奇伟、瑰怪，非常之观，常在于险远，而人之所罕至焉，故非有志者不能至也。有志矣，不随以止也，然力不足者，亦不能至也。有志与力，而又不随以怠，至于幽暗昏惑而无物以相之，亦不能至也。然力足以至焉，于人为可讥，而在己为有悔；尽吾志也而不能至者，可以无悔矣，其孰能讥之乎?</h6>
		<h6><a href="https://zh.m.wikisource.org/zh-hans/%E9%81%8A%E8%A4%92%E7%A6%AA%E5%B1%B1%E8%A8%98">《游褒禅山记》</a>-王安石 (C.E. 1054)</h6>
	</ul>				   
	<p>
		<center>
			<td><div id="clustrmaps-widget" style="width:40%">
			<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=wtR9heomb06BkrWYWQjyfCVMeVXskyN97vyGTiNyUTw"></script>
			</div></td>
			&copy; Yicheng Wu | Last updated: 2 Feb. 2024
		</center>
	</p>
</div>
</div>
</body></html>
