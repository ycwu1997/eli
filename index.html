<!DOCTYPE html>
<!--
My online resume
-->
<html><head>
<title>Yicheng (Eli) Wu's Homepage</title>

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css">
<style type="text/css">
 @import url("http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,300italic,600,600italic");


body
{
	font-family: 'Source Sans Pro', sans-serif;
    background-color : #CDCDCD;
    font-size: 17px;
}
    .content
	{
    		width : 1300px;
    		padding : 25px 20px;
    		margin : 25px auto;
    		background-color : #fff;
    		box-shadow: 0px 0px 10px #999;
    		border-radius: 15px; 
	}	
	table
	{
		padding: 5px;
	}
	
	table.pub_table,td.pub_td1,td.pub_td2
	{
		padding: 8px;
		width: 1200px;
        border-collapse: separate;
        border-spacing: 10px;
        margin-top: -10px;
	}

	td.pub_td1
	{
		width:50px;
	}
    td.pub_td1 img
    {
        height:120px;
        width: 160px;
    }
	
	div#container
	{
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
		text-align: justify;
		position: relative;
		background-color: #FFF;
	}
	div#DocInfo
	{
		color: #3B3B3B;
		height: 158px;
	}
	h4,h3,h2,h1
	{
		color: #3B3B3B;
	}
	h2
	{
		font-size:130%;
	}
	p
	{
		color: #5B5B5B;
		margin-bottom: 50px;
	}
	p.caption
	{
		color: #9B9B9B;
		text-align: left;
		width: 600px;
	}
	p.caption2
	{
		color: #9B9B9B;
		text-align: left;
		width: 800px;
	}
	#header_img
	{
		position: absolute;
		top: 0px; right: 0px;
    }
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
   
    table.pub_table tr {
        outline: thin dotted #666666;
    }
    .papericon {
        border-radius: 8px; 
        -moz-box-shadow: 3px 3px 6px #888;
        -webkit-box-shadow: 3px 3px 6px #888;
        box-shadow: 3px 3px 6px #888;
    }
</style>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('send', 'pageview');

</script>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-23931362-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

    var myPix = new Array("images/id.jpg")
    function choosePic() {
        var randomNum = Math.floor(Math.random() * myPix.length);
        document.getElementById("myPicture").src = myPix[randomNum];
    };

</script>
</head>


<body>
<div class="content">
	<div id="container">
<center>
	<table>
	<tbody><tr>
	<td><img id="myPicture" src="images/id.jpg" style="float:left; padding-right:10px" height="200px"></td>
	<td>
	<div id="DocInfo">
		<h1><strong>Yicheng(Eli) Wu 吴轶成</strong></h1>
						<h2>Research Associate</h2>
							Affiliation: Imperial College London<br />
							Current Address: Room 344, Huxley Building, South Kensington<br />
							Email: YCWUELI [at] GMAIL [dot] COM<br />
							<a href="https://scholar.google.com/citations?user=_h1y48MAAAAJ&hl=en">Google Scholar</a>
							&bull; <a href="https://github.com/ycwu1997">GitHub Repository</a>
							&bull; <a href="https://www.linkedin.com/in/yicheng-eli-wu-58a46b150/">LinkedIn</a>
						</div><br>
	</td>
	</tr>
	</tbody></table>
</center>
<br>
	<h2><strong>Biography</strong></h2>
	<ul>
		<li><strong>Introduction</strong></li>
			<ul>
			Yicheng Wu is now a postdoc at Imperial College London, working with <a href="https://www.doc.ic.ac.uk/~wbai/web/">A/Prof. Wenjia Bai</a>.
			Yicheng's research interests lie in computer vision and medical AI, with a focus on exploiting AI techniques to streamline clinical workflows and unlock new possibilities in medical practice. 
			More recently, he has been investigating generative modelling in medical imaging, aiming to develop universal foundation models capable of enhancing various clinical-route data.
			</ul>
		<li><strong>Working Experiences</strong></li>
			<ul>
			<li>2025.09-Present &nbsp;&nbsp; &bull;&nbsp;&nbsp; Research Associate &nbsp; &bull;&nbsp; Imperial College London</li>
			<li>2025.03-2025.09 &nbsp;&nbsp; &bull;&nbsp;&nbsp; Research Fellow &nbsp; &bull;&nbsp; Monash, Faculty of IT</li>
			<li>2023.03-2025.03 &nbsp;&nbsp; &bull;&nbsp;&nbsp; Research Assistant &nbsp; &bull;&nbsp; Monash, Faculty of IT</li>
			<li>2023.12-2024.06 &nbsp;&nbsp; &bull;&nbsp;&nbsp; Research Intern &nbsp; &bull;&nbsp; Shanghai AI Lab</li>
			<li>2020.08-2021.05 &nbsp;&nbsp; &bull;&nbsp;&nbsp; Research Intern &nbsp; &bull;&nbsp; Alibaba DAMO Academy</li>
			<li>2019.05-2020.08 &nbsp;&nbsp; &bull;&nbsp;&nbsp; Research Intern &nbsp; &bull;&nbsp; Deepwise AI Lab</li>
			</ul>
		<li><strong>Education Backgrounds</strong></li>
			<ul>
			<li>2021.06-2025.05 &nbsp; &bull;&nbsp;&nbsp; Doctor of Philosophy &nbsp; &bull;&nbsp; Supervisor: <a href="https://jianfei-cai.github.io/">Prof. Jianfei Cai</a> (IEEE Fellow) and <a href="https://zongyuange.github.io/">A/Prof. Zongyuan Ge</a>.<br></li> 
			<h6>Faculty of Information Technology, Monash University, Australia</h6>
			<li>2017.09-2020.04 &nbsp; &bull;&nbsp;&nbsp; Master of Engineering  &nbsp;&bull;&nbsp; Supervisor: <a href="https://teacher.nwpu.edu.cn/en/yongxia.html">Prof. Yong Xia</a>.<br></li>
			<h6>School of Computer Science and Engineering, Northwestern Polytechnical University, China</h6>
			<li>2018.11-2019.05 &nbsp; &bull;&nbsp; &nbsp;Visiting Scholar &nbsp; &bull;&nbsp; Supervisor: <a href="https://weidong-tom-cai.github.io/">A/Prof. Weidong(Tom) Cai</a> and <a href="http://www.cse.unsw.edu.au/~ysong/">A/Prof. Yang Song</a>.<br></li>
			<h6>School of Computer Science, The University of Sydney, Australia</h6>
			<li>2013.09-2017.06 &nbsp; &bull;&nbsp;&nbsp; Bachelor of Engineering &nbsp; &bull;&nbsp; Supervisor: <a href="https://teacher.nwpu.edu.cn/en/yongxia.html">Prof. Yong Xia</a>.<br></li>
			<h6>School of Computer Science and Engineering, Northwestern Polytechnical University, China</h6>
			</ul> 
	</ul>
    <h2><strong>News</strong></h2>
	<div style="height: 230px; overflow: auto;">
    	<ul>
		<li>[2025.09.20] I am very pleased to be listed in the Stanford/Elsevier World's Top 2% Scientists <a href="https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/8">2025</a>.</li>
		<li>[2025.09.06] I am very pleased to serve as an area chair in CVPR 2026.</li>
		<li>[2025.08.27] I will give a talk in the International Postdoc Academic Seminar of Visual Intelligence on 30 Augest 2025, see <a href="https://mp.weixin.qq.com/s/dBXVdb6BAalmFctsUCJOwA">here</a>.</li>
		<li>[2025.07.26] I will be joining the Faculty of Medicine at Imperial College London, as a research associate (postdoctoral researcher).</li>
		<li>[2025.07.25] Three of my <a href="https://scholar.google.com/citations?hl=en&view_op=list_hcore&venue=QLpioUFGyGMJ.2025">MICCAI</a>/<a href="https://scholar.google.com/citations?hl=en&view_op=list_hcore&venue=dlrWmqYJmF8J.2025">MedIA</a> works are ranked among the Top 20/40 most-cited papers (2020-2025, <a href="https://scholar.google.com/citations?view_op=metrics_intro&hl=en">Google Scholar</a>).</li>
		<li>[2025.06.19] One co-authored journal paper is accepted in npj Artificial Intelligence, about <a href="https://www.nature.com/articles/s44387-025-00016-8">brain MRI imputation</a>.</li>
		<li>[2025.06.18] Two co-authored papers are accepted in MICCAI 2025, about MS lesion and Polyp Segmentation.</li>
		<li>[2025.05.30] <strong>Got my PhD degree from Monash!</strong></li>
		<li>[2025.05.19] My PhD Thesis can be public accessed now, see <a href="https://bridges.monash.edu/articles/thesis/Data-centric_Medical_Image_Analysis_Addressing_Label_Scarcity_Variability_and_Modality_Incompleteness/29097233?file=54637421">here</a>.</li>
		<li>[2025.04.30] I will give a talk in the CV Dept. Seminar of MBZUAI. Thanks for Yutong's invitation.</li>
		<li>[2025.01.22] I will give a talk about my understanding on clinical label/data varability in the <a href="https://hit-webinar.com/">HIT Webinar</a>.</li>
		<li>[2025.01.17] I am very pleased to serve as an area chair in MICCAI 2025.</li>
		<li>[2024.12.12] I will be joining the Faculty of IT at Monash University, as a research fellow (postdoctoral researcher).</li>
		<li>[2024.10.01] Our team won the <a href="https://docs.google.com/spreadsheets/d/1yd86k9cPpW6DgKhS3bKsvQ1y5hBrFdEKDAxnG2zrWG8/edit?gid=0#gid=0">Runner-up</a> position in the MBH-Seg challenge at MICCAI 2024. Congrats. to <a href="https://jianghaowu.github.io/">Jianghao</a>.</li>
		<li>[2024.09.12] I am very pleased to share that our <a href="https://doi.org/10.1016/j.media.2022.102530">MC-Net+</a> work is selected as an <a href="https://www.webofscience.com/wos/woscc/full-record/WOS:000861027600004">ESI Highly Cited Paper</a>.</li>
		<li>[2024.06.18] We open the <a href="https://mmis2024.vercel.app/">MMIS-2024</a> grand challenge at ACM MM 2024. Welcome to join!</li>
		<li>[2024.04.09] I am very pleased to receive the <a href="https://cvpr.thecvf.com/Conferences/2024/DEI">CVPR DEI Support</a> and <a href="https://buildyourfuture.withgoogle.com/scholarships/google-conference-scholarships">Google Travel Grant</a> to attend CVPR 2024.</li>
		<li>[2024.02.27] One paper was accepted by CVPR 2024 (Highlight), about <a href="https://doi.org/10.1109/CVPR52733.2024.01090">Multi-rater Medical Image Segmentation</a>.</li>	
		<li>[2023.12.07] One journal paper was accepted by IJCV (IF-2023: 19.5), see <a href="https://doi.org/10.1007/s11263-023-01975-8">Paper</a> and <a href="https://github.com/wu-zhonghua/RAC-Net">Code</a>. Congrats. to <a href="https://wu-zhonghua.github.io/">Zhonghua</a>.</li>
		<li>[2023.10.12] I am very pleased to be selected as an IEEE Transactions on Medical Imaging (TMI) Distinguished Reviewer.</li>
		<li>[2023.07.25] I am very pleased to receive the <a href="https://www.monash.edu/it/news/2023/deans-awards-for-excellence-in-research">2023-FIT-Dean's Award</a> for Excellence in Research by a Graduate Research Student.</li>
		<li>[2023.07.11] One paper was early accepted by MICCAI 2023, about <a href="https://doi.org/10.1007/978-3-031-43993-3_1">Heterogeneous Data Training</a>.</li>
		<li>[2022.07.04] One paper was accepted by ECCV 2022, about <a href="https://doi.org/10.1007/978-3-031-19821-2_5">Weakly-Supervised Point Cloud Segmentation</a>.</li>
		<li>[2022.07.01] One journal paper was accepted by MedIA (IF-2022: 13.828), see <a href="https://doi.org/10.1016/j.media.2022.102530">here</a>.</li>
		<li>[2022.06.06] One journal paper was accepted by IEEE JBHI (IF-2022: 7.021), see <a href="https://doi.org/10.1109/JBHI.2022.3182471">here</a>. Congrats. to <a href="https://github.com/yeerwen">Yiwen</a>.</li>
		<li>[2022.06.03] Two papers were accepted by MICCAI 2022, about <a href="https://doi.org/10.1007/978-3-031-16443-9_4">Semi-supervised Segmentation</a> and <a href="https://doi.org/10.1007/978-3-031-16437-8_44">Long-tailed Classification</a>.</li>
		<li>[2022.03.03] One co-authored paper was accepted by CVPR 2022, about <a href="http://dx.doi.org/10.1109/cvpr52688.2022.00939">Unsupervised Proposal Generation</a>.</li>
		<li>[2021.06.11] One paper was accepted by MICCAI 2021.</li>
        <li>[2020.08.01] During my gap year, I will work as a research intern at DAMO Academy, Alibaba Group.</li>
		<li>[2020.05.12] I received the M.E. degree from Northwestern Polytechnical University, supervised by <a href="https://teacher.nwpu.edu.cn/en/yongxia.html">Prof. Yong Xia</a>.</li>
		<li>[2020.02.27] One journal paper was accepted by Neural Networks (IF-2020: 8.050).</li>
		<li>[2019.06.05] One paper was accepted by MICCAI 2019.</li>
		<li>[2018.05.31] I was selected as a co-authored master student supported by the China Scholarship Council (CSC).</li>
		<li>[2018.05.30] One paper was accepted by MICCAI 2018.</li>
		<li>[2017.06.20] I received the B.E. degree from Northwestern Polytechnical University, supervised by <a href="https://teacher.nwpu.edu.cn/en/yongxia.html">Prof. Yong Xia</a>.</li>
    	</ul>
	</div>
	<br>
	<h2><strong>Selected Publications </strong></h2> 
	<ul>
		* and <sup>†</sup> indicates the corresponding authorship and equal contribution, respectively.
	</ul>
	<h5><strong>Universal and Generative Medical Models</strong></h5>
	<table class="pub_table" >
		<tbody>
			<tr>
				<td class="pub_td1"><img src="images/sam_tta.png" class="papericon"></td>
				<td class="pub_td2">Jianghao Wu, <u>Yicheng Wu</u>*, Yutong Xie, Wenjia Bai, You Zhang, Feilong Tang, Yulong Li, Yasmeen George, and Imran Razzak<br><b>
					SAM-aware Test-time Adaptation for Universal Medical Image Segmentation</b><br> Under Review, 2025. [<a href="https://arxiv.org/pdf/2506.05221">Paper</a>]
			</td></tr>
			<tr>
				<td class="pub_td1"><img src="images/codebrain.png" class="papericon"></td>
				<td class="pub_td2"><u>Yicheng Wu<sup>†</sup></u>*, Tao Song<sup>†</sup>, Zhonghua Wu, Jin Ye, Zongyuan Ge, Zhaolin Chen, and Jianfei Cai<br><b>
					CodeBrain: Imputing Any Brain MRI via Modality- and Instance-Specific Codes</b><br> Under Review, 2025. [<a href="https://arxiv.org/pdf/2501.18328">Paper</a>]
			</td></tr>
			<tr>
				<td class="pub_td1"><img src="images/cvpr24.png" class="papericon"></td>
				<td class="pub_td2"><u>Yicheng Wu<sup>†</sup></u>*, Xiangde Luo<sup>†</sup>, Zhe Xu, Xiaoqing Guo, Lie Ju, Zongyuan Ge, Wenjun Liao, and Jianfei Cai<br><b>
					Diversified and Personalized Multi-rater Medical Image Segmentation</b><br> CVPR 2024 (Highlight), pp. 11470-11479, 2024. [<a href="https://doi.org/10.1109/CVPR52733.2024.01090">Paper</a>, <a href="https://github.com/ycwu1997/D-Persona">Code</a>]
			</td></tr>
		</tbody></table>

	<h5><strong>Data-efficent Medical Models</strong></h5>
	<table class="pub_table" >
	<tbody>
		<tbody>
			<tr>
			<td class="pub_td1"><img src="images/miccai23.png" class="papericon"></td>
			<td class="pub_td2"><u>Yicheng Wu*</u>, Zhonghua Wu, Hengcan Shi, Bjoern Picker, Winston Chong, and Jianfei Cai<br><b>
				CoactSeg: Learning from Heterogeneous Data for New Multiple Sclerosis Lesion Segmentation</b><br> MICCAI 2023, vol. 14227, pp. 3-13, 2023. [<a href="https://doi.org/10.1007/978-3-031-43993-3_1">Paper</a>, <a href="https://github.com/ycwu1997/CoactSeg">Code</a>]
		</td></tr>
		<tr>
			<td class="pub_td1"><img src="images/MC-Net+.jpg" class="papericon"></td>
			<td class="pub_td2"><u>Yicheng Wu*</u>, Zongyuan Ge, Donghao Zhang, Minfeng Xu, Lei Zhang, Yong Xia and Jianfei Cai<br><b>
				Mutual Consistency Learning for Semi-supervised Medical Image Segmentation</b><br> Medical Image Analysis (IF-2022: 13.828, ESI Highly Cited Paper), vol. 81, pp. 102530, 2022. [<a href="https://doi.org/10.1016/j.media.2022.102530">Paper</a>, <a href="https://github.com/ycwu1997/MC-Net">Code</a>]
		 </td></tr>
		 <tr>
			<td class="pub_td1"><img src="images/ijcv23.jpg" class="papericon"></td>
			<td class="pub_td2">Zhonghua Wu<sup>†</sup>, <u>Yicheng Wu</u><sup>†</sup>, Guosheng Lin* and Jianfei Cai<br><b>
				Reliability-Adaptive Consistency Regularization for Weakly-Supervised Point Cloud Segmentation</b><br> International Journal of Computer Vision (IF-2023: 11.6), vol. 132, pp. 2276-2289, 2024. [<a href="https://doi.org/10.1007/s11263-023-01975-8">Paper</a>, <a href="https://github.com/wu-zhonghua/RAC-Net">Code</a>]
		</td></tr>
		<tr>
			<td class="pub_td1"><img src="images/miccai22.png" class="papericon"></td>
			<td class="pub_td2"><u>Yicheng Wu*</u>, Zhonghua Wu, Qianyi Wu, Zongyuan Ge, and Jianfei Cai<br><b>
				Exploring Smoothness and Class-Separation for Semi-supervised Medical Image Segmentation</b><br>MICCAI 2022, vol. 13435, pp. 34-43, 2022. [<a href="https://doi.org/10.1007/978-3-031-16443-9_4">Paper</a>, <a href="https://github.com/ycwu1997/SS-Net">Code</a>]
		</td></tr>
		<tr>
			<td class="pub_td1"><img src="images/miccai21.png" class="papericon"></td>
			<td class="pub_td2"><u>Yicheng Wu</u>, Minfeng Xu, Zongyuan Ge, Jianfei Cai*, and Lei Zhang<br><b>
				Semi-supervised Left Atrium Segmentation with Mutual Consistency Training</b><br>MICCAI 2021, vol. 12902, pp. 297-306, 2021. [<a href="https://doi.org/10.1007/978-3-030-87196-3_28">Paper</a>, <a href="https://github.com/ycwu1997/MC-Net">Code</a>]
        </td></tr>
		<tr>
			<td class="pub_td1"><img src="images/eccv22.jpg" class="papericon"></td>
			<td class="pub_td2">Zhonghua Wu, <u>Yicheng Wu</u>, Guosheng Lin*, Jianfei Cai, and Chen Qian<br><b>
				Dual Adaptive Transformations for Weakly Supervised Point Cloud Segmentation</b><br> ECCV 2022, vol. 13691, pp. 78-96, 2022. [<a href="https://doi.org/10.1007/978-3-031-19821-2_5">Paper</a>, <a href="https://github.com/wu-zhonghua/DAT">Code</a>]
		</td></tr>
		<!--
		-->
	</tbody></table>
	<h5><strong>Effective Medical Models</strong></h5>
	<table class="pub_table" >
	<tbody>
		<tr>
			<td class="pub_td1"><img src="images/jbhi22.png" class="papericon"></td>
			<td class="pub_td2">Yiwen Ye<sup>†</sup>, Chengwei Pan<sup>†</sup>, <u>Yicheng Wu</u>, Shuqi Wang, and Yong Xia*<br><b>
				MFI-Net: Multiscale Feature Interaction Network for Retinal Vessel Segmentation</b><br>IEEE Journal of Biomedical and Health Informatics (IF-2022: 7.021), vol. 26(9), pp. 4551-4562, 2022. [<a href="https://doi.org/10.1109/JBHI.2022.3182471">Paper</a>]
		</td></tr>

		<tr>
			<td class="pub_td1"><img src="images/nn2020.png" class="papericon"></td>
			<td class="pub_td2"><u>Yicheng Wu</u>, Yong Xia*, Yang Song, Yanning Zhang, and Weidong Cai<br><b>
				NFN+: A Novel Network Followed Network for Retinal Vessel Segmentation</b><br>Neural Networks (IF-2020: 8.050), vol. 126, pp. 153-162, 2020. [<a href="https://doi.org/10.1016/j.neunet.2020.02.018">Paper</a>]
			</td></tr>

		<tr>
			<td class="pub_td1"><img src="images/miccai19.svg" class="papericon"></td>
			<td class="pub_td2"><u>Yicheng Wu</u>, Yong Xia*, Yang Song, Donghao Zhang, Dongnan Liu, Chaoyi Zhang, and Weidong Cai<br><b>
				Vessel-Net: Retinal Vessel Segmentation under Multi-path Supervision</b><br>MICCAI 2019, vol. 11764, pp. 264-272, 2019. [<a href="https://doi.org/10.1007/978-3-030-32239-7_30">Paper</a></h4>]
			</td></tr>

		<tr>
			<td class="pub_td1"><img src="images/miccai18.png" class="papericon"></td>
			<td class="pub_td2"><u>Yicheng Wu</u>, Yong Xia*, Yang Song, Yanning Zhang, and Weidong Cai<br><b>
				Multiscale Network Followed Network Model for Retinal Vessel Segmentation</b><br>MICCAI 2018, vol. 11071, pp. 119-126, 2018. [<a href="https://doi.org/10.1007/978-3-030-00934-2_14">Paper</a>]
			</td></tr>
	</tbody></table>
    <h2><strong>Academic Awards and Activities</strong></h2>
        <ul>
			<li>2025  &nbsp;&bull;&nbsp; Stanford/Elsevier World's Top 2% Scientists <a href="https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/8">2025</a> </li>
			<li>2025  &nbsp;&bull;&nbsp; MICCAI Travel Grant </li>
			<li>2024  &nbsp;&bull;&nbsp; Runner-up in the <a href="https://mbh-seg.com/">MBH-Seg</a> challenge at MICCAI 2024 </li>
			<li>2024  &nbsp;&bull;&nbsp; Google Travel Grant </li>
			<li>2024  &nbsp;&bull;&nbsp; CVPR DEI Support </li>
			<li>2023,2024  &nbsp;&bull;&nbsp; IEEE Transactions on Medical Imaging (TMI) Distinguished Reviewer </li>
			<li>2023 &nbsp;&bull;&nbsp; <a href="https://www.monash.edu/it/news/2023/deans-awards-for-excellence-in-research">2023-FIT-Dean's Award</a> for Excellence in Research by a Graduate Research Student </li>
			<li>2021-2024  &nbsp;&bull;&nbsp; Monash Graduate Scholarship (MGS) and Monash International Tuition Scholarship (MITS) </li>
            <li>2020  &nbsp;&bull;&nbsp; NPU Excellent Postgraduate Thesis Award (Top 3%) </li>
			<li>2019-2020  &nbsp;&bull;&nbsp; NPU Key Seed Foundation of Innovation and Creation for Graduate Students </li>
			<li>2019  &nbsp;&bull;&nbsp; Inspur Postgraduate Scholarship </li>
			<li>2018-2019 &nbsp;&bull;&nbsp; Scholarship from China Scholarship Council (Joint Master Student) </li>
			<li>2018  &nbsp;&bull;&nbsp; SJTU-USYD Research Conversazione Best Research Presentation </li>
			<li>2017  &nbsp;&bull;&nbsp; NPU Excellent Undergraduate Thesis Award (Top 7%) </li>
		</ul>
	<ul>
		<h5><li>Talks</li></h5>
			<ul>
			<li>2025.08.30  &nbsp;&bull;&nbsp; <a href="https://mp.weixin.qq.com/s/dBXVdb6BAalmFctsUCJOwA">International Postdoc Academic Seminar</a> hosted by Visual Intelligence </li>
			<li>2025.04.30  &nbsp;&bull;&nbsp; CV Dept. Weekly Morning Seminar in MBZUAI</li>
			<li>2025.01.24  &nbsp;&bull;&nbsp; <a href="https://hit-webinar.com/">HIT Webinar</a></li>
			</ul>
	</ul>
	<ul>
	<h5><li>Services</li></h5>
		    <ul>
			<li>2025  &nbsp;&bull;&nbsp; Area Chair in CVPR 2026 </li>
			<li>2025  &nbsp;&bull;&nbsp; Area Chair in MICCAI 2025 </li>
			<li>2024  &nbsp;&bull;&nbsp; Lead Organizer in the <a href="https://mmis2024.vercel.app/">MMIS-2024</a> Challenge at ACM MM 2024 </li>
			</ul>
	</ul>
	<ul>
		<h5><li>Reviews</li></h5>
		    <ul>
			<li>MICCAI</li>
			<li>NeurIPS; ICLR; ICML</li>
			<li>CVPR; ICCV; ECCV</li>
			<li>MedIA, IEEE TMI, J-BHI</li>
			<li>IJCV, IEEE TPAMI, TIP, TNNLS, TCSVT</li>
			<li>Computer Vision and Image Understanding</li>
			<li>Computer Methods and Programs in Biomedicine</li>
		</ul>
	</ul>
	<ul>
		<li>23-27 September 2025: MICCAI 2025, Daejeon, South Korea <strong><i>(Poster)</i></strong></li>
		<li>17-21 June 2024: CVPR 2024, Seattle, US <strong><i>(Highlight)</i></strong></li>
		<li>06-13 October 2023: MICCAI 2023, Vancouver, Canada <strong><i>(Poster)</i></strong></li>
		<li>18-22 September 2022: MICCAI 2022, Singapore <strong><i>(Poster)</i></strong></li>
		<li>27 September-01 October 2021: MICCAI 2021, Virtual Conference <strong><i>(Poster)</i></strong></li>
		<li>04-08 October 2020: OMIA7, Virtual Workshop <strong><i>(Online Presentation)</i></strong></li>
		<li>13-17 October 2019: MICCAI 2019, Shenzhen, China <strong><i>(Poster)</i></strong></li>
		<li>24 September 2019: MICS Webinar-MICCAI Conference <strong><i>(Online Oral Presentation)</i></strong></li>
		<li>13-14 July 2019: Medical Imaging Computing Seminar (MICS 2019), Suzhou, China <strong><i>(Poster)</i></strong></li>
		<li>23-26 November 2018: PRCV 2018, Guangzhou, China <strong><i>(Poster)</i></strong></li>
		<li>16-20 September 2018: MICCAI 2018, Granada, Spain <strong><i>(Poster)</i></strong></li>
		<li>20-22 April 2018: The 8th Vision and Learning Seminar (VALSE 2018), Dalian, China</li>
    </ul>
	<h2><strong>Curiosity</strong></h2>
	<ul>
		<h6>古人之观于天地、山川、草木、虫鱼、鸟兽，往往有得，以其求思之深而无不在也。夫夷以近，则游者众；险以远，则至者少。而世之奇伟、瑰怪，非常之观，常在于险远，而人之所罕至焉，故非有志者不能至也。有志矣，不随以止也，然力不足者，亦不能至也。有志与力，而又不随以怠，至于幽暗昏惑而无物以相之，亦不能至也。然力足以至焉，于人为可讥，而在己为有悔；尽吾志也而不能至者，可以无悔矣，其孰能讥之乎?</h6>
		<h6><a href="https://zh.m.wikisource.org/zh-hans/%E9%81%8A%E8%A4%92%E7%A6%AA%E5%B1%B1%E8%A8%98">《游褒禅山记》</a>-王安石 (C.E. 1054)</h6>
	</ul>				   
	<p>
		<center>
			<td><div id="clustrmaps-widget" style="width:40%">
			<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=wtR9heomb06BkrWYWQjyfCVMeVXskyN97vyGTiNyUTw"></script>
			</div></td>
			&copy; Yicheng Wu | Last updated: 06 Sep. 2025
		</center>
	</p>
</div>
</div>
</body></html>
